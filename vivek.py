# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vc7JC9dU72Cj4h4oEYsLN-LSRfx01_xT
"""

import torch
import torch.nn as nn

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Using:', device)

class CNN_network(nn.Module):
  #initialising the parameters for that init class
  def __init__(self):
    super(CNN_network,self).__init__()
    #this is inheriting the nn class from torch to our class
    #self.conv1=nn.Conv2d(in_channels=3,out_channels=16,kernel_size=3,stride=1,padding=0)
    self.model=nn.Sequential(
        #Layer 1
        nn.Conv2d(in_channels=3,out_channels=16,kernel_size=3,stride=1,padding=0),
        #here in_channels=3 as we are taking the colored image which have RGB channels
        nn.ReLU(),
        #a ReLU non-linearlty activation function
        nn.MaxPool2d(2,2),
        #a maxpool layer


        #Layer 2
        nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1,padding=0),
        #here in_channels=3 as we are taking the colored image which have RGB channels
        nn.ReLU(),
        #a ReLU non-linearlty activation function
        nn.MaxPool2d(2,2),
        #a maxpool layer

        #Layer 3
        nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=0),
        #here in_channels=3 as we are taking the colored image which have RGB channels
        nn.ReLU(),
        #a ReLU non-linearlty activation function
        nn.MaxPool2d(2,2),
        #a maxpool layer

        #Layer 4
        nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=0),
        #here in_channels=3 as we are taking the colored image which have RGB channels
        nn.ReLU(),
        #a ReLU non-linearlty activation function
        nn.MaxPool2d(2,2),
        #a maxpool layer

        nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=1,padding=0),
        #here in_channels=3 as we are taking the colored image which have RGB channels
        nn.ReLU(),
        #a ReLU non-linearlty activation function
        nn.MaxPool2d(2,2),
        #a maxpool layer
    ).to(device)

    self.classifier=nn.Sequential(
        nn.Flatten(),
        nn.Dropout(0.25),
        nn.Linear(4096,256),
        nn.ReLU(),
        nn.Dropout(0.5),
        nn.Linear(256,10)
    ).to(device)

    def forward(self,x):
      x=self.model(x)
      x=self.classifier(x)
      return x

class CNN_network(nn.Module):
  #initialising the parameters for that init class
  def __init__(self,layer):
    super(CNN_network,self).__init__()
    #this is inheriting the nn class from torch to our class
    #self.conv1=nn.Conv2d(in_channels=3,out_channels=16,kernel_size=3,stride=1,padding=0)
    self.network=[]
    for i in range(len(layer)):
      network[i]=nn.Sequential(
          nn.Conv2d(layer[i][0],layer[i][1],layer[i][2],layer[i][3],layer[i][4]),
          ReLU(),
          nn.MaxPool2d(2,2))



import torch
import torchvision
import torch.nn as nn
import torchvision.transforms as transforms

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

device

model = torchvision.models.vgg16(pretrained=True)

model

class Identity(nn.Module):
    def __init__(self):
        super(Identity, self).__init__()

    def forward(self, x):
        return x

for param in model.parameters():
    param.requires_grad = False

model.avgpool = Identity()
model.classifier = nn.Sequential(
    nn.Linear(512, 100), nn.ReLU(), nn.Linear(100, 10)
)
model.to(device)

alexnet = torchvision.models.alexnet(pretrained=True)

alexnet

model = torchvision.models.vgg16(pretrained=True)

for param in model.parameters():
  param.requires_grad=False

n_inputs=model.classifier[6].in_features
model.classifier=nn.Sequential(nn.Linear(n_inputs,256),nn.ReLU(),nn.Linear(256,10),nn.LogSoftmax(dim=1))

model

#part B

#(a) we will resize and transform the images with imagenet standards which is 224*224 and normalize it using the mean and standard_deviateions of imagenet dataset

# Image transformations
image_transform = {
    'transform':
    transforms.Compose([
        transforms.Resize(size=256),
        transforms.CenterCrop(size=224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}#call this when transform=image_transform[transform] when calling data

#(b) Imagenet has 1000 classes but we will make a custom classifier insetad of using the already present present clasifier as follows:

model = torchvision.models.vgg16(pretrained=True)

for param in model.parameters():
  param.requires_grad=False

n_inputs=model.classifier[6].in_features
model.classifier=nn.Sequential(nn.Linear(n_inputs,256),nn.ReLU(),nn.Linear(256,10),nn.LogSoftmax(dim=1))

#above we are using the custom classifee which will output 10 classes

#QUestion 2

#WE are freezing the first convoluation layers that is while backpropagation we will not be trainng the convolution layers by setting the 
for param in model.parameters():
  param.requires_grad=False
#requires_grad=False taht is setting their gradients equal to zero.

#also we will train only the last dense layers using backpropagation whcih will save a lot of time, that is we are using the weights and bias from 
#the imagenet dataset which is relatively large dataset

def finetune_model(model,n_classes):
    if model == 'vgg16':
        model = models.vgg16(pretrained=True)
        for param in model.parameters():
            param.requires_grad = False
        n_inputs = model.classifier[6].in_features
        model.classifier[6] = nn.Sequential(
            nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.2),
            nn.Linear(256, n_classes), nn.LogSoftmax(dim=1))
    if model == 'resnet50':
          model = models.resnet50(pretrained=True)
          for param in model.parameters():
              param.requires_grad = False
          n_inputs = model.fc.in_features
          model.fc = nn.Sequential(
              nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.2),
              nn.Linear(256, n_classes), nn.LogSoftmax(dim=1))
        return model/

